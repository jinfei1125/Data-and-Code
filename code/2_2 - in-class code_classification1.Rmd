---
title: "Classification, pt. 1"
author: "Philip Waggoner, MACS 30100 <br /> University of Chicago"
output: pdf_document
---

# Overview

Back to the 2016 ANES data for today. 

```{r}
# load some libraries
library(tidyverse)
library(here)
library(patchwork)
library(tidymodels)

# load the 2016 ANES pilot study data
anes <- read_csv(here("data", "anes_pilot_2016.csv"))

# select some features and clean: party, and 2 fts
anes_short <- anes %>% 
  select(pid3, fttrump, ftobama) %>% 
  mutate(democrat = as.factor(ifelse(pid3 == 1, 1, 0)),
         fttrump = replace(fttrump, fttrump > 100, NA),
         ftobama = replace(ftobama, ftobama > 100, NA)) %>%
  drop_na()

anes_short <- anes_short %>% 
  select(-c(pid3)) %>% 
  relocate(c(democrat))

anes_short %>% 
  skimr::skim()
```

Fit to full data. 

```{r}
# model fitting via tidymodels
# define mod and engine
mod <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

# fit 
logit <- mod %>% 
  fit(democrat ~ ., 
      data = anes_short)

# eval
logit %>% 
  predict(anes_short) %>% 
  bind_cols(anes_short) %>% 
  metrics(truth = democrat,
          estimate = .pred_class)

# predict and viz
logit %>% 
  predict(anes_short) %>% 
  mutate(model = "logit", 
         truth = anes_short$democrat) %>% 
  mutate(correct = if_else(.pred_class == truth, "Yes", "No")) %>% 
  ggplot() +
  geom_bar(alpha = 0.8, aes(correct, fill = correct)) + 
  labs(x = "Correct?",
       y = "Count",
       fill = "Correctly\nClassified") +
  theme_minimal()
```

Explore.

```{r}
# explore some of the output
library(broom)

tidy(logit)
```

Predicted probabilities. 

```{r}
dont_like_trump <- tibble(fttrump = 0:10,
                          ftobama = mean(anes_short$ftobama))

predicted_probs <- predict(logit, 
                           dont_like_trump, 
                           type = "prob")
# visualize results
dont_like_trump %>%
  bind_cols(predicted_probs) %>%
  ggplot(aes(x = fttrump, 
             y = .pred_1)) +
  geom_point() +
  geom_errorbar(aes(ymin = (.pred_1) - sd(.pred_1), 
                    ymax = (.pred_1) + sd(.pred_1)), 
                width = 0.2) +
  geom_hline(yintercept = 0.50, linetype = "dashed") +
  ylim(0, 1) +
  labs(x = "Feelings toward Trump",
       y = "Probability of Being a Democrat") + 
  theme_minimal()
```

Hmm... what happened?

```{r}
dont_like_trump_love_obama <- tibble(fttrump = 0:10,
                                     ftobama = 90:100)

predicted_probs_new <- predict(logit, 
                               dont_like_trump_love_obama, 
                               type = "prob")
# visualize results
dont_like_trump_love_obama %>%
  bind_cols(predicted_probs_new) %>%
  ggplot(aes(x = fttrump, 
             y = .pred_1)) +
  geom_point() +
  geom_errorbar(aes(ymin = (.pred_1) - sd(.pred_1), 
                    ymax = (.pred_1) + sd(.pred_1)), 
                width = 0.2) +
  geom_hline(yintercept = 0.50, linetype = "dashed") +
  ylim(0, 1) +
  labs(x = "Feelings toward Trump",
       y = "Probability of Being a Democrat") + 
  theme_minimal()
```

Cross-validating a final, full model (from start to finish).

```{r}
## split
set.seed(1234)

split <- initial_split(anes_short,
                       prop = 0.70) 
train <- training(split)
test <- testing(split)

cv_train <- vfold_cv(train, 
                     v = 10)

## Now, create a recipe
recipe <- recipe(democrat ~ ., 
                 data = anes_short) 


# define mod and engine
mod <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")


# Define a workflow
workflow <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(mod)

res <- workflow %>%
  fit_resamples(resamples = cv_train,
                metrics = metric_set(roc_auc, accuracy))


# finalize workflow and evaluate
final <- res %>% 
  select_best(metric = "accuracy")

# Define a workflow; This is just a way to keep things neat and tidy (pun intended)
workflow <- workflow %>%
  finalize_workflow(final)

final_mod <- workflow %>%
  last_fit(split) 


# inspect (if desired)
final_mod %>% 
  collect_predictions() 

final_mod %>%  
  collect_metrics() 

# create confusion matrix based on predictions from the model with conf_mat() from the yardstick package
final_mod %>% 
  collect_predictions() %>% 
  conf_mat(truth = democrat, 
           estimate = .pred_class,
           dnn = c("Pred", "Truth"))

# bar plot
final_mod %>% 
  collect_predictions() %>% 
  ggplot() +
  geom_bar(aes(x = .pred_class, 
               fill = democrat)) +
  facet_wrap(~ democrat) +
  labs(title = "From Logit Fit",
       x = "Predicted Party Affiliations", 
       fill = "Democrat",
       caption = "Note: facets are ground truth") +
  theme_minimal()
```

## Penalized Logistic Regression

What about a penalized logistic regression? Take a look at the replication materials (<https://github.com/pdwaggoner/crim_algs>) for a paper I co-authored with a student, predicting criminal recidivism for real criminal defendants. The paper is on the arXiv (<https://arxiv.org/abs/2011.06422>) if you'd like to read it. But the code combines this week's material with last week's material. It's an opportunity to see some of this in action. 

# On your own

For this section, you will work in small groups of 4-5. *I will create these groups at random*. 

**IMPORTANT**: _Don't forget that this code you're working on here is due at the appropriate Canvas module (in the form of an attachment to a "Discussion" post) prior to 5:00 pm CDT tomorrow. You need only submit a **single** file/script to be considered for credit (i.e., this .Rmd with your code inserted below each question). Recall, I don't care whether you got things right. I only care that attempts to each question have been made._ 

Let’s end by taking a look at some other features’ effects on predicting party affiliation. Recall, we just said the classifier does a decent job at predicting party ID, but these are only two very specific features (feelings toward more recent, polarizing figures in American politics). So let’s expand the scope a bit. 

1. Create a new subset of the full 2016 ANES data including the party id feature we have been working with (that is the dichotomous version we created), along with *all* feeling thermometers. Drop `NA`s after creating the subset.

2. Fit a new logistic regression classifier predicting party affiliation as a function of all feeling thermometers in your subset data. Present the coefficients from the output. 

3. Recreate the bar plot from earlier depicting the accuracy of your solution. 
